{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Pandas Transformation Lab\n",
    "\n",
    "_Authors: Riley Dallas (ATX), Dave Yerrington (SF), Mark Popovich (SF)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this lab, you'll get some practice concatenating Pandas dataframes and plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Scikit Learn comes pre-loaded with a number of datasets. Today we'll be working with the canonical iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Munging Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Scikit Learn datasets are actually functions that return an object containing the data we need. \n",
    "\n",
    "In the cell below, call the `load_iris()` function and set the result to a variable called `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Target Data\n",
    "\n",
    "In machine learning, the column we're trying to predict is usually called the **target** (or **label**). \n",
    "\n",
    "**To see the targets for our dataset, call `data['target']` in the cell below.**\n",
    "\n",
    " Also, you can use `data.keys()` to see a list of elements available inside the `data` object.\n",
    "```python\n",
    " dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the iris dataset, the target is the particular species of iris flower. Because machine learning requires our features and target to be numbers, the species are encoded as 0, 1, 2. These indices correspond to the labeled species on `data.target_names`\n",
    "\n",
    "**Call `data['target_names']` to see the actual names of the three species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the length of `data['target']` to see how many flowers are in this dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `species` DataFrame\n",
    "\n",
    "**Use `data['target']` to create your first pandas DataFrame, which is just a single column (`\"species\"`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Feature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features for this dataset are on `data['data']`. There are 150 rows, one for each flower and 4 columns, one for each of the following features:\n",
    "1. sepal length (cm)\n",
    "2. sepal width (cm)\n",
    "3. petal length (cm)\n",
    "4. petal width (cm)\n",
    "\n",
    "**Output `data['data']` in the cell below to see the features for this dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `features` DataFrame\n",
    "\n",
    "Create a `features` DataFrame in pandas, using `data['data']` and `data['feature_names']` \n",
    "\n",
    "You can use `pd.DataFrame()` to create a DataFrame, passing the `columns` parameter using `data['feature_names']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pd.concat`\n",
    "\n",
    "**Use `pd.concat` to combine the two dataframes.**\n",
    "\n",
    "- The concat method essentially squishes two dataframes together, along either Axis 0 or Axis 1.\n",
    "- Axis 0 here refers to the rows. If we concat along axis 0, we would be stacking one DataFrame on top of the other. That is not what we want to accomplish in this case.\n",
    "- Instead, we want to put the two dataframes side-by-side. In order to do that, we concat the columns by using Axis 1.\n",
    "- Review / research the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) on the useage of this function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `df.join`\n",
    "\n",
    "Compare concat with `DataFrame.join` by joining the two original DataFrames instead.\n",
    "\n",
    "In this case, we do not have to specify an axis. Join here is explicitly for joining two or more dataframes on columns. You can even pass a list of DataFrames to join if you have more than one (they must all have the same column to join on). Refer to the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `df.merge`\n",
    "\n",
    "Compare concat with `DataFrame.merge` by merging the two original DataFrames instead.\n",
    "\n",
    "Like join, merge does not function across rows. Additionally, you will note that without a common column to merge on, you must be explicit about telling pandas to merge on the right and left indices. You can do this with `left_index=True` and `right_index=True`. Because we are not merging on a column, we do not pass `on` or `how` parameters, but both of those parameters will become very important to you as you do more sophisticated merging. Refer to the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Features List\n",
    "\n",
    "Create a list of all the numeric column names by dropping the species column, then calling the `columns` attribute followed by the `values` attribute. Save it to a variable named `num_cols`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to reference the order of your numeric columns (so just print them out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert an Interaction Column\n",
    "\n",
    "Multiply the four numeric columns together and save them as a new column `interaction`.\n",
    "\n",
    "Inserting a new column is as easy as:\n",
    "```\n",
    "df['new_column_name_as_string'] = values\n",
    "```\n",
    "The `values` here can be many different things:\n",
    "- a `pd.Series` that shares an index with our DataFrame will align perfectly and no NaNs will be present.\n",
    "- a list or array of the same length as our DataFrame will also align perfectly.\n",
    "- a single value will set that value for all rows.\n",
    "\n",
    "(It's also important to note that when we set a value at a specific location in a new column, all unspecified locations will be filled with NaNs.)\n",
    "\n",
    "**We can use `apply` and `lambda` to do this. Here's an example:**\n",
    "\n",
    "To get the sepal area (len * width), we can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's break down this code:**\n",
    "```\n",
    "df.apply(lambda x: x[num_cols[0]] * x[num_cols[1]], axis=1)\n",
    "```\n",
    "\n",
    "First, let's remember that:\n",
    "- `num_cols[0] == 'sepal length (cm)'`\n",
    "- `num_cols[1] == 'sepal width (cm)'`\n",
    "\n",
    "The apply function will allow us to pass a function over an axis of our DataFrame:\n",
    "- here, we specify `axis=1`, which means that we are grabbing all of our rows and applying our function to their columns.\n",
    "\n",
    "`lambda` functions are disposable, and often just use the variable `x` as a placeholder for whatever they're operating on:\n",
    "- because we're operating on our rows, `x` becomes a row each time our function is applied.\n",
    "- we can specify which columns we want to operate on, noting that those column values will be multiplied by the same column in that row.\n",
    "\n",
    "Thus, we can basically read this code as:\n",
    "```\n",
    "For each row in df, multiply sepal length (cm) by sepal width (cm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, do this for ALL numeric columns and assign this the new column `interaction`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return All Rows for a Subset of Columns\n",
    "\n",
    "There are lots of ways to select data of interest in a DataFrame.\n",
    "\n",
    "Use the `.loc` method to display all of the rows (`:`) and only the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can do this same thing just by passing a list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert `target_names`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's insert a string (object in pandas) encoded column from the species column for human-readable labels. \n",
    "\n",
    "Let's look at our `target_names` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our `species` column.\n",
    "\n",
    "*Using `.value_counts()` will get us the count for each of our classes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not extremely well documented, the order of `data.target_names` corresponds with our numeric targets.\n",
    "\n",
    "\n",
    "We'll start by writing a dictionary `species_name` by using a dictionary comprehension on the `data['target_names']` array from the original iris dataset. We'll use the `enumerate` function as an easy way to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at those key value pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the `map` pandas method on the `species` column with the `species_name` dict. Save the result to `df['labels']`.\n",
    "\n",
    "**Why this works:**\n",
    "\n",
    "When we `map` a dict to a Series, we pass each value of the Series as a key to our dict. Here, our `species` are the integers `[0, 1, 2]` which are the keys in our dict, so we access the corresponding species name currently stored as our values.\n",
    "\n",
    "**Note**: `map` is much like `apply`, but only applies to a single column (a Pandas series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "We'll start by importing our plotting packages using their preferred aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot\n",
    "\n",
    "Create a pairplot from your dataframe. Use the seaborn package to do so (`sns.pairplot`) and pass the argument `hue` with the column `'labels'`. This will use the labels column we created above to both color the scatterpoints and create a legend. Add a semicolon `;` at the end of your plotting code to prevent unsightly output above the chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate one histogram for each of the 4 original numeric columns. Use at least 3 different plotting methods to do so. (pandas built-in, matplotlib, seaborn). BONUS: Use plotly for one of the histograms. \n",
    "\n",
    "Hint: for seaborn you will want `sns.distplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn distplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BONUS: Plotly\n",
    "\n",
    "If you want to get started with plotly, you will need to pip install the two packages above and then head to [plotly](https://plot.ly/feed/#/) and like the sign-up button. After you create your account, you will see a field marked API Key. Click the `Regenerate Key` button to display a new api key, then copy and paste that with your username into the field below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly histogram\n",
    "#!pip install plotly --upgrade\n",
    "#!pip install cufflinks --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to get plotly to work, you will need to create a username and api_key\n",
    "# the following code writes your credentials to a static file, \n",
    "# so you will only ever need to run it once. \n",
    "import plotly \n",
    "plotly.tools.set_credentials_file(username='', api_key='')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
